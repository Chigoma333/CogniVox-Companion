#your discord token
DISCORD_TOKEN = ""
#The url to your oogabooga api
MODEL_URL = ""

#Gives Debug Information for the LLM model
LLM_DEBUG = "True"

#If set to 0 whisper (stt) will not be used [0/1]
USE_WHISPER = "1"
#Set wihsper model. small is faster and uses less RAM, but has a worse reuslt then base. [small/base]
WHISPER_MODEL = "small"


#If set to 0 tortoise (tts) will not be used (Cant be 1 if USE_BARK = 1)[0/1]
USE_TORTOISE = "1"

#tortoise voice model https://github.com/neonbjb/tortoise-tts/tree/main/tortoise/voices or use a custom one simply put 3-5 .wav files of the voice you want to use inside voices/CUSTOM_NAME/ then you would need to set TORTOISE_VOICE = "CUSTOM_NAME".Default "angie"
TORTOISE_VOICE = "angie"

#tortoise Diffusion Iterations (higher is better but slower) i recommend 50
TORTOISE_DIFFUSION_ITERATIONS = 50

#tortoise number of autoregressive samples (higher is better but slower) i recommend 2
TORTOISE_NUM_AUTOREGRESSIVE_SAMPLES = 2

#tortoise temperature (higher gives more random results) i recommend 0.2
TORTOISE_TEMPERATURE = 0.2

#tortoise use deepspeed (faster but needs CUDA) and you need to install deepspeed with "pip install deepspeed" [True/False]
TORTOISE_USE_DEEPSPEED = "False"

#tortoise use kv cache [True/False]
TORTOISE_KV_CACHE = "True"

#tortoise half loads the model into half precision (faster and uses less RAM) should give worse results [True/False]
TORTOISE_HALF = "True"


#If set to 0 bark (tts) will not be used (Cant be 1 if USE_TORTOISE = 1) [0/1]
USE_BARK = "0"

#Setting it to 1 makes bark faster and use less RAM, but the tradeoff is that the results might not be as good compared to setting it to 0. [0/1]
BARK_USE_SMALL_MODEL = 1

#SPeaker from bark you can find a list here https://github.com/suno-ai/bark/tree/main/bark/assets/prompts (use v2 they are better)
BARK_SPEAKER = "v2/en_speaker_7"
